{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as ds\n",
    "from torchvision import models, transforms, utils, datasets\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from WebScraping import search_and_download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_df = pd.read_csv(\"data/fish_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Images Using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 101.0.4951\n",
      "Get LATEST chromedriver version for 101.0.4951 google-chrome\n",
      "Driver [/home/shivaram/.wdm/drivers/chromedriver/linux64/101.0.4951.41/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "for ind, row in fish_df.iterrows():\n",
    "    searchterm_reg_name = row[\"FishBase name\"]\n",
    "    searchterm_sci_name = row[\"Species\"]\n",
    "    save_folder = str(row[\"fishbase_id\"])\n",
    "    number_images = 500\n",
    "    target_path = '/media/shivaram/SharedVolum/Projects/FishID/scraped_images/' \n",
    "    \n",
    "    if os.path.exists(target_path + \"scientific/\" + save_folder):\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Working on {searchterm_reg_name} ({searchterm_sci_name})\")\n",
    "    \n",
    "    if searchterm_reg_name == searchterm_reg_name:\n",
    "        search_and_download(searchterm_reg_name, \"regular/\" + save_folder , driver = driver, number_images=number_images)\n",
    "    if searchterm_sci_name == searchterm_sci_name:\n",
    "        search_and_download(searchterm_sci_name, \"scientific/\" + save_folder, driver = driver, number_images=number_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Images for Not Fish\n",
    "My IsFish model was built on a somewhat controlled dataset (mini-imagenet and fishbase images). As a result, it will naturally perform more poorly on this real world data. To get a better understanding of its performance, I preview the classifications as well as the model's confidence in them. In doing so, I learned a few things, namely that:\n",
    "- The model seems to struggle with maps and text images with images within them. \n",
    "- Lowering the threshold to -1 or -.5 (instead of 0) for the deltas decreases the number of false negatives while minimally increasing the false positives. \n",
    "\n",
    "Based on these findings, I decided to add some images of maps to the IsFish Classifier and retrain it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3060 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "model_ft.load_state_dict(torch.load(\"models/is_fish.pt\"))\n",
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224)), ]) #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species 972\n"
     ]
    }
   ],
   "source": [
    "regular_path = \"/media/shivaram/SharedVolum/Projects/FishID/scraped_images/scientific\" \n",
    "# For each species folder\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    for folder in os.listdir(regular_path):\n",
    "        print(f\"Species {folder}\")\n",
    "        if i == 0:\n",
    "            break\n",
    "        \n",
    "        # For each image in species folder\n",
    "        fish_count = 0\n",
    "        not_fish_count = 0\n",
    "        deltas = []\n",
    "        for file in os.listdir(regular_path + \"/\" + folder):\n",
    "            image_path = regular_path + \"/\" + folder + \"/\" + file\n",
    "            try:\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "            except:\n",
    "                continue\n",
    "            img_filt = data_transforms(img).cuda().unsqueeze(0)\n",
    "            outputs = model_ft(img_filt)\n",
    "            \n",
    "            _, preds =torch.max(outputs, 1)\n",
    "            preds = preds.tolist()\n",
    "            delta = outputs.tolist()[0][0] - outputs.tolist()[0][1]\n",
    "            preds = preds[0]\n",
    "            \n",
    "            if preds == 0:\n",
    "                fish_count += 1\n",
    "                print(delta)\n",
    "                display(img)\n",
    "                \n",
    "            else:\n",
    "                not_fish_count += 1\n",
    "                #if delta < -1.5:\n",
    "                #  display(image)\n",
    "                deltas.append(delta)\n",
    "            \n",
    "\n",
    "        i += 1\n",
    "        print(fish_count)\n",
    "        print(not_fish_count)\n",
    "        print(deltas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  1.,  3.,  4.,  5.,  7.,  5.,  6.,  4.,  8., 12.,  9., 11.,\n",
       "        15., 15., 16., 24., 16., 20., 15.]),\n",
       " array([-7.8954854 , -7.50132999, -7.10717458, -6.71301917, -6.31886376,\n",
       "        -5.92470835, -5.53055294, -5.13639753, -4.74224212, -4.34808671,\n",
       "        -3.9539313 , -3.55977589, -3.16562048, -2.77146507, -2.37730966,\n",
       "        -1.98315425, -1.58899884, -1.19484343, -0.80068802, -0.40653261,\n",
       "        -0.0123772 ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(deltas, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_transforms = transforms.Compose([transforms.ToTensor(),\\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\\nimage_dataset = datasets.ImageFolder(\"data/fishbase_images/\",data_transforms)\\ndataLoader = torch.utils.data.DataLoader(image_dataset, batch_size=64, num_workers=4)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "dataLoader = torch.utils.data.DataLoader(image_dataset, batch_size=64, num_workers=4)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://medium.com/geekculture/scraping-images-using-selenium-f35fab26b122\n",
    "- https://stackoverflow.com/questions/10543940/check-if-a-url-to-an-image-is-up-and-exists-in-python\n",
    "https://stackoverflow.com/questions/295135/turn-a-string-into-a-valid-filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
