{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as ds\n",
    "from torchvision import models, transforms, utils, datasets\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from PIL import Image\n",
    "from WebScraping import search_and_download\n",
    "\n",
    "import splitfolders\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_df = pd.read_csv(\"data/fish_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Images Using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 101.0.4951\n",
      "Get LATEST chromedriver version for 101.0.4951 google-chrome\n",
      "Driver [/home/shivaram/.wdm/drivers/chromedriver/linux64/101.0.4951.41/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "for ind, row in fish_df.iterrows():\n",
    "    searchterm_reg_name = row[\"FishBase name\"]\n",
    "    searchterm_sci_name = row[\"Species\"]\n",
    "    save_folder = str(row[\"fishbase_id\"])\n",
    "    number_images = 500\n",
    "    target_path = '/media/shivaram/SharedVolum/Projects/FishID/scraped_images/' \n",
    "    \n",
    "    if os.path.exists(target_path + \"scientific/\" + save_folder):\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Working on {searchterm_reg_name} ({searchterm_sci_name})\")\n",
    "    \n",
    "    if searchterm_reg_name == searchterm_reg_name:\n",
    "        search_and_download(searchterm_reg_name, \"regular/\" + save_folder , driver = driver, number_images=number_images)\n",
    "    if searchterm_sci_name == searchterm_sci_name:\n",
    "        search_and_download(searchterm_sci_name, \"scientific/\" + save_folder, driver = driver, number_images=number_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Images for Not Fish\n",
    "My IsFish model was built on a somewhat controlled dataset (mini-imagenet and fishbase images). As a result, it will naturally perform more poorly on this real world data. To get a better understanding of its performance, I preview the classifications as well as the model's confidence in them. In doing so, I learned a few things, namely that:\n",
    "- The model seems to struggle with maps and text images with images within them. \n",
    "- Lowering the threshold to -1 or -.5 (instead of 0) for the deltas decreases the number of false negatives while minimally increasing the false positives. \n",
    "\n",
    "Based on these findings, I decided to add some images of maps to the IsFish Classifier and retrain it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3060 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.1 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "model_ft.load_state_dict(torch.load(\"models/is_fish.pt\"))\n",
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224)), ]) #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivaram/anaconda3/envs/pytorch/lib/python3.9/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "regular_path = \"/media/shivaram/SharedVolum/Projects/FishID/scraped_images/scientific\" \n",
    "show_image = True\n",
    "# For each species folder\n",
    "i = 0\n",
    "is_fish_data = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for folder in os.listdir(regular_path):\n",
    "        #print(f\"Species {folder}\")\n",
    "        if i == -1:\n",
    "            break\n",
    "        \n",
    "        # For each image in species folder\n",
    "        fish_count = 0\n",
    "        not_fish_count = 0\n",
    "        deltas = []\n",
    "        for file in os.listdir(regular_path + \"/\" + folder):\n",
    "            image_path = regular_path + \"/\" + folder + \"/\" + file\n",
    "            try:\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "            except:\n",
    "                continue\n",
    "            img_filt = data_transforms(img).cuda().unsqueeze(0)\n",
    "            outputs = model_ft(img_filt)\n",
    "            \n",
    "            _, preds =torch.max(outputs, 1)\n",
    "            preds = preds.tolist()\n",
    "            fish_score = outputs.tolist()[0][0]\n",
    "            not_fish_score = outputs.tolist()[0][1]\n",
    "            delta = fish_score - not_fish_score \n",
    "            preds = preds[0]\n",
    "            # 1 is for not fish and 0 is for fish\n",
    "            mod_pred = delta > -2\n",
    "            \n",
    "            is_fish_data.append([folder, file, mod_pred, delta])\n",
    "            \n",
    "            \"\"\"if delta > -2 and delta < 0:\n",
    "                print(delta)\n",
    "                print(preds)\n",
    "                #print(outputs.tolist()[0][0])\n",
    "                #print(outputs.tolist()[0][1])\n",
    "                #display(img)\"\"\"\n",
    "            \n",
    "            if mod_pred == 1:\n",
    "                fish_count += 1\n",
    "                \"\"\"if show_image:\n",
    "                    display(img)\"\"\"\n",
    "                \n",
    "            else:\n",
    "                not_fish_count += 1 \n",
    "                deltas.append(delta)\n",
    "            \n",
    "\n",
    "        i += 1\n",
    "        \n",
    "        #print(fish_count)\n",
    "        #print(not_fish_count)\n",
    "        #print(deltas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fish_df = pd.DataFrame(is_fish_data, columns = [\"Species\", \"Filename\", \"Is Fish?\", \"Delta Score\"])\n",
    "is_fish_df.to_csv(\"data/is_fish.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1265"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(is_fish_df[\"Species\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete all Gifs, Remove Bad Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/shivaram/SharedVolum/Projects/FishID/scraped_images/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m path\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*/*/*.gif\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      6\u001b[0m     filename\u001b[38;5;241m.\u001b[39munlink()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/pathlib.py:1190\u001b[0m, in \u001b[0;36mPath.rglob\u001b[0;34m(self, pattern)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-relative patterns are unsupported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1189\u001b[0m selector \u001b[38;5;241m=\u001b[39m _make_selector((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m\"\u001b[39m,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(pattern_parts), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour)\n\u001b[0;32m-> 1190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m selector\u001b[38;5;241m.\u001b[39mselect_from(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m p\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/pathlib.py:611\u001b[0m, in \u001b[0;36m_RecursiveWildcardSelector._select_from\u001b[0;34m(self, parent_path, is_dir, exists, scandir)\u001b[0m\n\u001b[1;32m    609\u001b[0m successor_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuccessor\u001b[38;5;241m.\u001b[39m_select_from\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m starting_point \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterate_directories(parent_path, is_dir, scandir):\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m successor_select(starting_point, is_dir, exists, scandir):\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m yielded:\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m p\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/pathlib.py:575\u001b[0m, in \u001b[0;36m_WildcardSelector._select_from\u001b[0;34m(self, parent_path, is_dir, exists, scandir)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch(name):\n\u001b[1;32m    574\u001b[0m             path \u001b[38;5;241m=\u001b[39m parent_path\u001b[38;5;241m.\u001b[39m_make_child_relpath(name)\n\u001b[0;32m--> 575\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuccessor\u001b[38;5;241m.\u001b[39m_select_from(path, is_dir, exists, scandir):\n\u001b[1;32m    576\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m p\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mPermissionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/pathlib.py:575\u001b[0m, in \u001b[0;36m_WildcardSelector._select_from\u001b[0;34m(self, parent_path, is_dir, exists, scandir)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch(name):\n\u001b[1;32m    574\u001b[0m             path \u001b[38;5;241m=\u001b[39m parent_path\u001b[38;5;241m.\u001b[39m_make_child_relpath(name)\n\u001b[0;32m--> 575\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuccessor\u001b[38;5;241m.\u001b[39m_select_from(path, is_dir, exists, scandir):\n\u001b[1;32m    576\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m p\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mPermissionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/pathlib.py:559\u001b[0m, in \u001b[0;36m_WildcardSelector._select_from\u001b[0;34m(self, parent_path, is_dir, exists, scandir)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m scandir(parent_path) \u001b[38;5;28;01mas\u001b[39;00m scandir_it:\n\u001b[0;32m--> 559\u001b[0m         entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscandir_it\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entries:\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdironly:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Remove all gifs (can't be read by pytorch)\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"/media/shivaram/SharedVolum/Projects/FishID/scraped_images/\")\n",
    "for filename in path.rglob(\"*/*/*.gif\"):\n",
    "    filename.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_dir(path):\n",
    "    try:\n",
    "        os.rmdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "def remove_all_empty_dirs(base_path):\n",
    "    for root, dirnames, filenames in os.walk(base_path, topdown=False):\n",
    "        for dirname in dirnames:\n",
    "            remove_empty_dir(os.path.realpath(os.path.join(root, dirname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/media/shivaram/SharedVolum/Projects/FishID/scraped_images/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirnames, filenames in os.walk(base_path, topdown=True):\n",
    "    \n",
    "    if not filenames:\n",
    "        continue\n",
    "    for file in filenames:\n",
    "        full_path = root + \"/\" + file\n",
    "        try:\n",
    "            img = Image.open(full_path)\n",
    "            img.verify()\n",
    "        except(IOError,SyntaxError)as e:\n",
    "            print('Bad file  :  ' + file + \"! Removing...\")\n",
    "            os.remove(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_empty_dirs(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://medium.com/geekculture/scraping-images-using-selenium-f35fab26b122\n",
    "- https://stackoverflow.com/questions/10543940/check-if-a-url-to-an-image-is-up-and-exists-in-python\n",
    "https://stackoverflow.com/questions/295135/turn-a-string-into-a-valid-filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
